{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import load_img\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.models import load_model\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tf_explain.core.smoothgrad import SmoothGrad\n",
    "from keras.utils import img_to_array, load_img\n",
    "import cv2\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import PIL.Image\n",
    "from matplotlib import pylab as P\n",
    "import saliency.core as saliency\n",
    "\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 251 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you provide the same target size as initialied for the image size\n",
    "training_set = train_datagen.flow_from_directory('../../Covid19-dataset/train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 66 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('../../Covid19-dataset/test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../../models/covid/covid_vgg1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_set)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 75267     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,789,955\n",
      "Trainable params: 75,267\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate methods.\n",
    "def ShowImage(im, title='', ax=None):\n",
    "  if ax is None:\n",
    "    P.figure()\n",
    "  P.axis('off')\n",
    "  P.imshow(im)\n",
    "  P.title(title)\n",
    "\n",
    "def ShowGrayscaleImage(im, title='', ax=None):\n",
    "  if ax is None:\n",
    "    P.figure()\n",
    "  P.axis('off')\n",
    "\n",
    "  P.imshow(im, cmap=P.cm.gray, vmin=0, vmax=1)\n",
    "  P.title(title)\n",
    "\n",
    "def ShowHeatMap(im, title, ax=None):\n",
    "  if ax is None:\n",
    "    P.figure()\n",
    "  P.axis('off')\n",
    "  P.imshow(im, cmap='inferno')\n",
    "  P.title(title)\n",
    "\n",
    "def LoadImage(file_path):\n",
    "  im = PIL.Image.open(file_path)\n",
    "  im = im.resize((224,224))\n",
    "  im = np.asarray(im)\n",
    "  return im\n",
    "\n",
    "def PreprocessImage(im):\n",
    "  im = tf.keras.applications.vgg16.preprocess_input(im)\n",
    "  return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model_function(im, call_model_args=None, expected_keys=None):\n",
    "    # Get the logits tensor from the model\n",
    "    logits_tensor = model.output\n",
    "\n",
    "    # Get the input tensor\n",
    "    input_tensor = model.input\n",
    "\n",
    "    # Calculate gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_tensor)\n",
    "        logits = logits_tensor[0, call_model_args['prediction_class']]\n",
    "    gradients = tape.gradient(logits, input_tensor)\n",
    "    return gradients.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image_grayscale(image_3d):\n",
    "    # Convert the 3D tensor to 2D grayscale\n",
    "    grayscale_image = np.mean(image_3d, axis=-1)\n",
    "    # Rescale the values to [0, 1]\n",
    "    grayscale_image -= np.min(grayscale_image)\n",
    "    grayscale_image /= np.max(grayscale_image)\n",
    "    # Convert the values to the range [0, 255] and cast to uint8\n",
    "    grayscale_image = (grayscale_image * 255).astype(np.uint8)\n",
    "    # Resize the image to 224x224\n",
    "    grayscale_image_resized = cv2.resize(grayscale_image, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "    return grayscale_image_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded and preprocessed.\n",
      "Gradient computation function defined.\n",
      "Saliency masks computed.\n",
      "Saliency masks converted to grayscale.\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:699: error: (-215:Assertion failed) image.channels() == 1 || image.channels() == 3 || image.channels() == 4 in function 'cv::imwrite_'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 51\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSaliency maps saved as \u001b[39m\u001b[39m'\u001b[39m\u001b[39mvanilla_mask_grayscale.png\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39msmoothgrad_mask_grayscale.png\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[39m# Call the generate_saliency_maps function with an image path and your model\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m generate_saliency_maps(\u001b[39m'\u001b[39;49m\u001b[39m../../Covid19-dataset/test/Covid/0100.jpeg\u001b[39;49m\u001b[39m'\u001b[39;49m, model, \u001b[39m'\u001b[39;49m\u001b[39m2\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[76], line 44\u001b[0m, in \u001b[0;36mgenerate_saliency_maps\u001b[1;34m(image_path, model, class_idx_str)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSaliency masks converted to grayscale.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[39m# Save the results as image files\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m cv2\u001b[39m.\u001b[39;49mimwrite(\u001b[39m'\u001b[39;49m\u001b[39mvanilla_mask_grayscale.png\u001b[39;49m\u001b[39m'\u001b[39;49m, vanilla_mask_grayscale)\n\u001b[0;32m     45\u001b[0m cv2\u001b[39m.\u001b[39mimwrite(\u001b[39m'\u001b[39m\u001b[39msmoothgrad_mask_grayscale.png\u001b[39m\u001b[39m'\u001b[39m, smoothgrad_mask_grayscale)\n\u001b[0;32m     47\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSaliency maps saved as \u001b[39m\u001b[39m'\u001b[39m\u001b[39mvanilla_mask_grayscale.png\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39msmoothgrad_mask_grayscale.png\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:699: error: (-215:Assertion failed) image.channels() == 1 || image.channels() == 3 || image.channels() == 4 in function 'cv::imwrite_'\n"
     ]
    }
   ],
   "source": [
    "def generate_saliency_maps(image_path, model, class_idx_str):\n",
    "    # Load and preprocess the image\n",
    "    im = load_img(image_path, target_size=(224, 224))\n",
    "    im = img_to_array(im)\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    im = preprocess_input(im)\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "\n",
    "    print(\"Image loaded and preprocessed.\")\n",
    "\n",
    "    # Get the index of the target class\n",
    "    prediction_class = int(class_idx_str)\n",
    "\n",
    "    # Define a function to compute the gradients\n",
    "    def compute_gradients(x_value_batch, call_model_args=None, expected_keys=None):\n",
    "        x_value = x_value_batch[0]  # Unbatch the input\n",
    "        x_value = tf.convert_to_tensor(x_value)  # Convert the input to a TensorFlow tensor\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(x_value)\n",
    "            output = model(x_value)\n",
    "            class_output = output[:, prediction_class]\n",
    "\n",
    "        gradients = tape.gradient(class_output, x_value)\n",
    "        gradients_batched = np.expand_dims(gradients, axis=0)  # Add the batch dimension\n",
    "        return {saliency.INPUT_OUTPUT_GRADIENTS: gradients_batched}\n",
    "\n",
    "    print(\"Gradient computation function defined.\")\n",
    "\n",
    "    gradient_saliency = saliency.GradientSaliency()\n",
    "\n",
    "    # Compute the vanilla mask and the smoothed mask.\n",
    "    vanilla_mask_3d = gradient_saliency.GetMask(im[0], compute_gradients)\n",
    "    smoothgrad_mask_3d = gradient_saliency.GetSmoothedMask(im[0], compute_gradients)\n",
    "\n",
    "    print(\"Saliency masks computed.\")\n",
    "\n",
    "    # Call the visualization methods to convert the 3D tensors to 2D grayscale.\n",
    "    vanilla_mask_grayscale = visualize_image_grayscale(vanilla_mask_3d)\n",
    "    smoothgrad_mask_grayscale = visualize_image_grayscale(smoothgrad_mask_3d)\n",
    "\n",
    "    print(\"Saliency masks converted to grayscale.\")\n",
    "\n",
    "    # Save the results as image files\n",
    "    cv2.imwrite('vanilla_mask_grayscale.png', vanilla_mask_grayscale)\n",
    "    cv2.imwrite('smoothgrad_mask_grayscale.png', smoothgrad_mask_grayscale)\n",
    "\n",
    "    print(\"Saliency maps saved as 'vanilla_mask_grayscale.png' and 'smoothgrad_mask_grayscale.png'.\")\n",
    "\n",
    "\n",
    "# Call the generate_saliency_maps function with an image path and your model\n",
    "generate_saliency_maps('../../Covid19-dataset/test/Covid/0100.jpeg', model, '2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded and preprocessed.\n",
      "Gradient computation function defined.\n",
      "Saliency masks computed.\n",
      "Saliency masks converted to grayscale.\n",
      "Saliency maps saved as 'vanilla_mask_grayscale.png' and 'smoothgrad_mask_grayscale.png'.\n"
     ]
    }
   ],
   "source": [
    "def visualize_image_grayscale(image_3d):\n",
    "    # Convert the 3D tensor to 2D grayscale\n",
    "    grayscale_image = np.mean(image_3d, axis=-1)\n",
    "    # Rescale the values to [0, 1]\n",
    "    grayscale_image -= np.min(grayscale_image)\n",
    "    grayscale_image /= np.max(grayscale_image)\n",
    "    # Convert the values to the range [0, 255] and cast to uint8\n",
    "    grayscale_image = (grayscale_image * 255).astype(np.uint8)\n",
    "    # Resize the image to 224x224\n",
    "    grayscale_image_resized = cv2.resize(grayscale_image, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "    return grayscale_image_resized\n",
    "\n",
    "\n",
    "def generate_saliency_maps(image_path, model, class_idx_str):\n",
    "    # Load and preprocess the image\n",
    "    im = load_img(image_path, target_size=(224, 224))\n",
    "    im = img_to_array(im)\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    im = preprocess_input(im)\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "\n",
    "    print(\"Image loaded and preprocessed.\")\n",
    "\n",
    "    # Get the index of the target class\n",
    "    prediction_class = int(class_idx_str)\n",
    "\n",
    "    # Define a function to compute the gradients\n",
    "    def compute_gradients(x_value_batch, call_model_args=None, expected_keys=None):\n",
    "        x_value = x_value_batch[0]  # Unbatch the input\n",
    "        x_value = tf.convert_to_tensor(x_value)  # Convert the input to a TensorFlow tensor\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(x_value)\n",
    "            output = model(x_value)\n",
    "            class_output = output[:, prediction_class]\n",
    "\n",
    "        gradients = tape.gradient(class_output, x_value)\n",
    "        gradients_batched = np.expand_dims(gradients, axis=0)  # Add the batch dimension\n",
    "        return {saliency.INPUT_OUTPUT_GRADIENTS: gradients_batched}\n",
    "\n",
    "    print(\"Gradient computation function defined.\")\n",
    "\n",
    "    gradient_saliency = saliency.GradientSaliency()\n",
    "\n",
    "    # Compute the vanilla mask and the smoothed mask.\n",
    "    vanilla_mask_3d = gradient_saliency.GetMask(im[0], compute_gradients)\n",
    "    smoothgrad_mask_3d = gradient_saliency.GetSmoothedMask(im[0], compute_gradients)\n",
    "\n",
    "    print(\"Saliency masks computed.\")\n",
    "\n",
    "    # Call the visualization methods to convert the 3D tensors to 2D grayscale.\n",
    "    vanilla_mask_grayscale = visualize_image_grayscale(vanilla_mask_3d)\n",
    "    smoothgrad_mask_grayscale = visualize_image_grayscale(smoothgrad_mask_3d)\n",
    "\n",
    "    print(\"Saliency masks converted to grayscale.\")\n",
    "\n",
    "    # Save the results as image files\n",
    "    cv2.imwrite('vanilla_mask_grayscale.png', vanilla_mask_grayscale)\n",
    "    cv2.imwrite('smoothgrad_mask_grayscale.png', smoothgrad_mask_grayscale)\n",
    "\n",
    "    print(\"Saliency maps saved as 'vanilla_mask_grayscale.png' and 'smoothgrad_mask_grayscale.png'.\")\n",
    "\n",
    "    # Print out the input image and the saliency maps\n",
    "    input_image = cv2.imread(image_path)\n",
    "    input_image_resized = cv2.resize(input_image, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.imshow(\"Input Image\", input_image_resized)\n",
    "    cv2.imshow(\"Vanilla Saliency Map\", vanilla_mask_grayscale)\n",
    "    cv2.imshow(\"SmoothGrad Saliency Map\", smoothgrad_mask_grayscale)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Call the generate_saliency_maps function with an image path and your model\n",
    "generate_saliency_maps('../../Covid19-dataset/test/Covid/0100.jpeg', model, '2')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
